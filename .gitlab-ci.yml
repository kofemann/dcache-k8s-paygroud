#
# test pipeline with k8s integration
#


stages:
  - prepare
  - test_deploy
  - testing
  - collect
  - cleanup

variables:
  NS: build-$CI_PIPELINE_ID
  CHECK_TIMEOUT: --timeout=300s
  AUTOCA_URL: https://ci.dcache.org:8083/
  CONTEXT: c-kmghz:p-w824c


#
# prepare kubernetes env for the build
#
prepare_env:
  stage: prepare
  image: fjuette/docker-rancher-cli
  script:
    - rancher login --token $RANCHER_TOKEN $RANCHER_ENDPOINT --context $CONTEXT
    - rancher namespace create $NS


deploy:
  stage: test_deploy
  image: fjuette/docker-rancher-cli
  tags:
    - kubernetes
  script:
    - kubectl config set-context --current --namespace=$NS

    - kubectl apply -f deployments/postgresql-service.yml
    - kubectl apply -f deployments/zookeeper.yml
    - kubectl apply -f deployments/dcache-service.yml
    - while ! kubectl get pod -l app=dcache-door; do sleep 1; done
    - kubectl wait $CHECK_TIMEOUT --for=condition=Ready pod -l app=dcache-door

  environment:
    testing


cvmfs_test:
  stage: test_deploy
  image: centos:7
  tags:
    - cvmfs
  script:
    - yum -y install redhat-lsb-core libtool-ltdl curl python openssl libxslt glibmm24 zlib libuuid krb5-libs
    - tests/grid-test.sh

pynfs_tests:
  stage: testing
  allow_failure: true
  image: fjuette/docker-rancher-cli
  tags:
    - kubernetes
  script:
    - kubectl config set-context --current --namespace=$NS

    - kubectl run pynfs-tester --image=dcache/pynfs:0.1 --restart=Never  --command -- sleep 3600
    - kubectl wait $CHECK_TIMEOUT --for=condition=Ready pods --all

    - kubectl exec pynfs-tester -- /bin/bash -c "cd /pynfs/nfs4.0; python3 -u ./testserver.py --xml=/xunit-report-v40.xml --maketree dcache-svc:/data all; exit 0"
    - kubectl exec pynfs-tester -- /bin/bash -c "cd /pynfs/nfs4.1; python3 -u ./testserver.py --xml=/xunit-report-v41.xml --maketree dcache-svc:/data all; exit 0"

    - kubectl cp pynfs-tester:/xunit-report-v40.xml xunit-report-v40.xml
    - kubectl cp pynfs-tester:/xunit-report-v41.xml xunit-report-v41.xml
  environment:
    testing

  artifacts:
    reports:
      junit:
        - "xunit*.xml"

xrdcp_tests:
  stage: testing
  allow_failure: true
  image: fjuette/docker-rancher-cli
  tags:
    - kubernetes
  script:
    - kubectl config set-context --current --namespace=$NS

    - kubectl run xrdcp-tester --image=centos:7 --restart=Never  --command -- sleep 3600
    - kubectl wait $CHECK_TIMEOUT --for=condition=Ready pods --all

    - kubectl exec xrdcp-tester -- yum install -y epel-release
    - kubectl exec xrdcp-tester -- yum install -y xrootd-client
    - kubectl exec xrdcp-tester -- xrdcp /etc/hosts root://dcache-svc/tests/file.data
    - kubectl exec xrdcp-tester -- xrdcp root://dcache-svc/tests/file.data /tmp/file.data
    - kubectl exec xrdcp-tester -- cmp /etc/hosts /tmp/file.data
  environment:
    testing



collect_logs:
  stage: collect
  image: fjuette/docker-rancher-cli
  tags:
    - kubernetes
  when: always
  allow_failure: true
  script:
    - kubectl config set-context --current --namespace=$NS
    - kubectl logs -l app=dcache-door --all-containers --tail=-1 > dcache-door.log
    - kubectl logs -l app=dcache-pool --all-containers --tail=-1 > dcache-pool.log
    - kubectl logs -l app=postgresql --all-containers --tail=-1 > postgres.log
    - kubectl logs -l app=zk --all-containers --tail=-1 > zk.log
  environment:
    testing
  artifacts:
    paths:
    - "*.log"


#
# dispose kubernetes resources
#
cleanup:
  stage: cleanup
  image: fjuette/docker-rancher-cli
  when: always
  script:
    - rancher login --token $RANCHER_TOKEN $RANCHER_ENDPOINT --context $CONTEXT
    - rancher namespace delete $NS


